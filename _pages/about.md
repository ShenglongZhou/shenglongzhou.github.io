---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<style>
a:link {
  text-decoration: none;
}

a:visited {
  text-decoration: none;
}

a:hover {
  text-decoration: underline;
}

a:active {
  text-decoration: underline;
}
</style>



<b style="font-size:20px">Employment History</b>
---
Professor, 2023 - present <br>
<a style="color:#015697" href='http://soms.bjtu.edu.cn/' target="_blank">School of Mathematics and Statistics </a>, <a style="color:#015697" href='https://www.bjtu.edu.cn/' target="_blank">Beijing Jiaotong University</a>, China 

Research Fellow, 2021-2023 <br>
<a href='https://www.imperial.ac.uk/electrical-engineering' target="_blank">Department of EEE</a>,
<a style="color:#015697" href='https://www.imperial.ac.uk/' target="_blank">Imperial College London</a>, UK <br>
<br>
Teaching Fellow, 2020-2021 <br>
Research Fellow, 2017-2020 <br>
<a style="color:#015697" href='https://www.southampton.ac.uk/maths' target="_blank">School of Mathematics</a>, <a style="color:#015697" href='https://www.southampton.ac.uk/' target="_blank">University of Southampton</a>, UK <br>


<b style="font-size:20px">Education Background</b>
---
PhD in  Operational Research, 2014-2017 <br>
School of Mathematics, University of Southampton, UK <br>
<br>
MSc in Operational Research, 2011-2014 <br>
BSc in Information and Computing Sciences, 2007-2011 <br>
Department of Mathematics, Beijing Jiaotong University, China 



<b style="font-size:20px">Research Interests</b> 
---
<p><div style="text-align:justify;"> 
My research interests encompass the theory and methods of optimization, including sparse and low-rank optimization, 0/1 loss optimization, and distributed optimization, with applications in artificial intelligence, signal processing, machine learning, etc.
</div></p> 


<b style="font-size:20px">Computational Platforms</b> 
---
Sparse optimization computation platform: <a style="font-size: 16px; font-weight: bold; color:#015697"  href="https://sparseopt.github.io/" target="_blank">SparseOpt</a>-ENG, <a style="font-size: 16px; font-weight: bold; color:#015697"  href="https://sparseopt-cn.github.io/" target="_blank">SparseOpt</a>-CN<br>
Bilevel optimization computation platform: <a style="font-size: 16px; font-weight: bold; color:#015697"  href="https://biopt.github.io/" target="_blank">BiOpt</a><br>
 

<b style="font-size:20px">Selected Publications</b>
---

A full list of publications can be found here -
<a style="font-size: 16px; font-weight: bold; color:#015697"  href="https://shenglongzhou.github.io/publications/" target="_blank">More Papers</a>

<font size=4>
<div style="text-align:justify"> 

[10] Shenglong Zhou, Lili Pan, Naihua Xiu, and Geoffrey Ye Li, A 0/1 constrained optimization solving sample average approximation for chance constrained programming, <a style="font-style: italic; color:#015697" href="https://pubsonline.informs.org/doi/10.1287/moor.2023.0149" target="_blank">Mathematics of Operations Research</a>, 2024. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/364588009" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2210.11889" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/SNSCO" target="_blank">Code</a>
<p style="line-height: -0.5em"></p>

[9] Shenglong Zhou and Geoffrey Ye Li, Federated learning via inexact ADMM,
<a style="font-style: italic; color:#015697"  href="https://ieeexplore.ieee.org/document/10040221" target="_blank">IEEE Transactions on Pattern Analysis and Machine Intelligence</a>, 45, 9699-9708, 2023. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/360164168" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2204.10607" target="_blank">ArXiv</a>, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/FedADMM" target="_blank">Code</a>
 <p style="line-height:-0.5em"></p>
  
[8] Shenglong Zhou, Sparse SVM for sufficient data reduction, 
<a style="font-style: italic; color:#015697" href="https://ieeexplore.ieee.org/document/9415153" target="_blank">IEEE Transactions on Pattern Analysis and Machine Intelligence</a>, 44, 5560-5571, 2022. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/351035522" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2005.13771" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/NSSVM" target="_blank">Code</a> 
<p style="line-height: 1;"></p>
  
[7] Shenglong Zhou, Gradient projection Newton pursuit for sparsity constrained optimization, 
<a style="font-style: italic; color:#015697" href="https://doi.org/10.1016/j.acha.2022.06.002" target="_blank">Applied and Computational Harmonic Analysis</a>, 61, 75-100, 2022. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/360476606" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2205.04580" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/GPNP" target="_blank">Code</a> 
<p style="line-height: 1;"></p>
  
[6] Shenglong Zhou, Ziyan Luo, Naihua Xiu, and Geoffrey Ye Li, Computing one-bit compressive sensing via double-sparsity constrained optimization, 
<a style="font-style: italic; color:#015697" href="https://ieeexplore.ieee.org/document/9729395" target="_blank">IEEE Transactions on Signal Processing</a>, 70, 1593-1608, 2022.
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/348371863" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2101.03599" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/GPSP" target="_blank">Code</a> 
<p style="line-height: 1;"></p>
  
[5] Shenglong Zhou, Lili Pan, Naihua Xiu, and Huoduo Qi, Quadratic convergence of smoothing Newton's method for 0/1 loss optimization, 
<a style="font-style: italic; color:#015697" href="https://epubs.siam.org/doi/abs/10.1137/21M1409445" target="_blank">SIAM Journal on Optimization</a>, 31, 3184–3211, 2021. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/354744779" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2103.14987" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/NM01" target="_blank">Code</a>
<p style="line-height: 1;"></p>

[4] Shenglong Zhou, Lili Pan, Mu Li, and Meijuan Shang, Newton hard-thresholding pursuit for sparse linear complementarity problem via a new merit function, 
<a style="font-style: italic; color:#015697" href="https://doi.org/10.1137/19M1301539" target="_blank">SIAM Journal on Scientific Computing</a>, 43, A772–A799, 2021. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/337948990" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2004.02244" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/NHTPver2" target="_blank">Code</a> 
<p style="line-height: 1;"></p>

[3] Shenglong Zhou, Naihua Xiu, and Huoduo Qi, Global and quadratic convergence of Newton hard-thresholding pursuit, 
<a style="font-style: italic; color:#015697" href="https://jmlr.org/papers/v22/19-026.html" target="_blank">Journal of Machine Learning Research</a>, 22, 1−45, 2021. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/330224407" target="_blank">RG</a>, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/1901.02763" target="_blank">ArXiv</a>, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/NHTPver2" target="_blank">Code</a>
<p style="line-height: 1;"></p>
  
[2] Shenglong Zhou, Naihua Xiu, and Huoduo Qi, Robust Euclidean embedding via EDM optimization,
<a style="font-style: italic; color:#015697"  href="https://link.springer.com/article/10.1007/s12532-019-00168-0" target="_blank">Mathematical Programming Computation</a>, 12, 337–387, 2019. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/PREEEDM" target="_blank">Code</a> 
<p style="line-height: 1;"></p>

[1] Shenglong Zhou, Naihua Xiu, and Huoduo Qi, A fast matrix majorization-projection method for penalized stress minimization with box constraints, 
<a style="font-style: italic; color:#015697"   href="https://ieeexplore.ieee.org/document/8399531" target="_blank">IEEE Transactions on Signal Processing</a>, 66, 4331-4346, 2018. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/SQREDM" target="_blank">Code</a>
<p style="line-height: 1;"></p>

</div>
</font> 


<!---
<p><div style="text-align:justify"> 
 For sparse  optimization, several first-order methods <a style="font-size: 16px; font-weight: bold; color:#015697" href="https://github.com/ShenglongZhou/MIRL1" target="_blank">MIRL1</a>, <a style="font-size: 16px; font-weight: bold; color:#015697" href="https://github.com/ShenglongZhou/IIHT" target="_blank">IIHT</a> and <a style="font-size: 16px; font-weight: bold; color:#015697" href="https://github.com/ShenglongZhou/HTPCP" target="_blank">HTPCP</a>, and second-order methods  <a style="font-size: 16px; font-weight: bold; color:#015697" href="https://github.com/ShenglongZhou/NHTPver2" target="_blank">NHTP</a>, <a style="font-size: 16px; font-weight: bold; color:#015697" href="https://github.com/ShenglongZhou/NHTPver2" target="_blank">NL0R</a> and <a style="font-size: 16px; font-weight: bold; color:#015697" href="https://github.com/ShenglongZhou/NHTPver2" target="_blank">NSSVM</a>, have been developed to solve the compressed sensing, logistic regression, linear complementarity problems, support vector machines, and etc.  
</div></p>

<p><div style="text-align:justify">
For Euclidean distance matrix optimization, the majorization techniques were adopted to design competitively fast algorithms packaged into two solvers <a style="font-size: 16px; font-weight: bold; color:#015697" href="https://github.com/ShenglongZhou/PREEEDM" target="_blank">PREEEDM</a> and <a style="font-size: 16px; font-weight: bold;  color:#015697" href="https://github.com/ShenglongZhou/SQREDM" target="_blank">SQREDM</a>. 
</div></p>

 <p><div style="text-align:justify">
 For bilevel optimization, a Matlab-based <a style="font-size: 16px; font-weight: bold; color:#015697" href="https://biopt.github.io/" target="_blank">BiOpt Toolbox</a> has been created, aiming at providing a platform on which users can test a wide range collection of bilevel optimization examples from <a style="font-size: 16px; font-weight: bold; color:#015697" href="https://biopt.github.io/" target="_blank">BOLIBver2</a> through three self-provided solvers and several useful tools. 
</div></p>

--->
