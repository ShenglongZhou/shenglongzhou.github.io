---
layout: single
title: ""
permalink: /publications/
author_profile: true
redirect_from:
  - /resume
---
<style>
a:link {
  text-decoration: none;
}

a:visited {
  text-decoration: none;
}

a:hover {
  text-decoration: underline;
}

a:active {
  text-decoration: underline;
}
</style>

## <b style="font-size:20px"> 0/1 Loss Optimization</b>

<font size=4>
<div style="text-align:justify"> 
  
[6] Shenglong Zhou, Lili Pan, Naihua Xiu, and Geoffrey Ye Li, A 0/1 constrained optimization solving sample average approximation for chance constrained programming, <a style="font-style: italic; color:#015697" href="https://pubsonline.informs.org/doi/10.1287/moor.2023.0149" target="_blank">Mathematics of Operations Research</a>, 2024. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/364588009" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2210.11889" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/SNSCO" target="_blank">Code</a>
<p style="line-height: -0.5"></p>

[5] Shenglong Zhou, Ziyan Luo, Naihua Xiu, and Geoffrey Ye Li, Computing one-bit compressive sensing via double-sparsity constrained optimization, 
<a style="font-style: italic; color:#015697" href="https://ieeexplore.ieee.org/document/9729395" target="_blank">IEEE Transactions on Signal Processing</a>, 70, 1593-1608, 2022.
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/348371863" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2101.03599" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/GPSP" target="_blank">Code</a> 
 <p style="line-height: -0.5"></p>
 
[4] Shenglong Zhou, Lili Pan, Naihua Xiu, and Huoduo Qi, Quadratic convergence of smoothing Newton's method for 0/1 loss optimization, 
<a style="font-style: italic; color:#015697" href="https://epubs.siam.org/doi/abs/10.1137/21M1409445" target="_blank">SIAM Journal on Optimization</a>, 31, 3184–3211, 2021. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/354744779" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2103.14987" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/NM01" target="_blank">Code</a>
<p style="line-height: 1"></p>
  
[3] Huajun Wang, Yuanhai Shao,  Shenglong Zhou, Ce Zhang, and Naihua Xiu, Support vector machine classifier via L0/1 soft-margin loss, 
 <a style="font-style: italic; color:#015697" href="https://doi.org/10.1109/TPAMI.2021.3092177" target="_blank">IEEE Transactions on Pattern Analysis and Machine Intelligence</a>, 44, 7253-7265, 2022. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/338717629" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/1912.07418" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/Huajun-Wang/L01ADMM" target="_blank">Code</a>
<p style="line-height: 1"></p>

<details>
<summary><span style="color:#015697"><b style="font-size:16px">Click for more papers</b></span></summary>
<p style="line-height: 1;"></p> 
  
[2] Hui Zhang, Shenglong Zhou, Geoffrey Ye Li, Naihua Xiu, and Yiju Wang,  A step function based recursion method for 0/1 deep neural networks,
 <a style="font-style: italic; color:#015697" href="https://doi.org/10.1016/j.amc.2024.129129" target="_blank">Applied Mathematics and Computation</a>, 488, 1-16, 2025. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/361411821" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2206.09379" target="_blank">ArXiv</a>
<p style="line-height: 1;"></p> 

[1] Shenglong Zhou, Lili Pan, and Naihua Xiu, Heaviside set constrained optimization: optimality and Newton method, 2020.
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/343362652" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2007.15737" target="_blank">ArXiv</a>
<p style="line-height: 1;"></p>

</details>

</div>
</font> 

## <b style="font-size:20px">Sparse Optimization</b>

<font size=4> 
<div style="text-align:justify">
  
[20] Shuai Li, Shenglong Zhou, and Ziyan Luo, Sparse quadratically constrained quadratic programming via semismooth Newton method, 2025. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/389974763" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2503.15109" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/SNSQP" target="_blank">Code</a> 
<p style="line-height: 1;"></p>
  
[19] Jun Fan, Jie Sun, Ailin Yan, and Shenglong Zhou, An oracle gradient regularized Newton method for quadratic measurements regression, 
<a style="font-style: italic; color:#015697" href="https://doi.org/10.1016/j.acha.2025.101775" target="_blank">Applied and Computational Harmonic Analysis</a>, 78, 101775, 2025. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/358730474" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2202.09651" target="_blank">ArXiv</a>
<p style="line-height: 1;"></p>

[18] Shenglong Zhou, Xianchao Xiu, Yingnan Wang, and Dingtao Peng, Revisiting Lq (0<=q<1) norm regularized optimization, 2023. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/371855733" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2306.14394" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/PNPLq" target="_blank">Code</a> 
<p style="line-height: 1;"></p>

[17] Shenglong Zhou, Gradient projection newton pursuit for sparsity constrained optimization, 
<a style="font-style: italic; color:#015697" href="https://doi.org/10.1016/j.acha.2022.06.002" target="_blank">Applied and Computational Harmonic Analysis</a>, 61, 75-100, 2022. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/360476606" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2205.04580" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/GPNP" target="_blank">Code</a> 
<p style="line-height: 1;"></p>
  
[16] Shenglong Zhou, Sparse SVM for sufficient data reduction, 
<a style="font-style: italic; color:#015697" href="https://ieeexplore.ieee.org/document/9415153" target="_blank">IEEE Transactions on Pattern Analysis and Machine Intelligence</a>, 44, 5560-5571, 2022. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/351035522" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2005.13771" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/NSSVM" target="_blank">Code</a> 
<p style="line-height: 1;"></p>
  
[15] Shenglong Zhou, Naihua Xiu, and Huoduo Qi, Global and quadratic convergence of Newton hard-thresholding pursuit, 
<a style="font-style: italic; color:#015697" href="https://jmlr.org/papers/v22/19-026.html" target="_blank">Journal of Machine Learning Research</a>, 22, 1−45, 2021. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/330224407" target="_blank">RG</a>, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/1901.02763" target="_blank">ArXiv</a>, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/NHTPver2" target="_blank">Code</a>
<p style="line-height: 1;"></p>
  
[14] Shenglong Zhou, Lili Pan, and Naihua Xiu, Newton method for L0-regularized optimization,
<a style="font-style: italic; color:#015697" href="https://doi.org/10.1007/s11075-021-01085-x" target="_blank">Numerical Algorithms</a>, 88, 1541–1570, 2021.
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/340563338" target="_blank">RG</a>, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2004.05132" target="_blank">ArXiv</a>, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/NL0R" target="_blank">Code</a> 
<p style="line-height: 1;"></p>
  
[13] Shenglong Zhou, Lili Pan, Mu Li, and Meijuan Shang, Newton hard-thresholding pursuit for sparse linear complementarity problem via a new merit function, 
<a style="font-style: italic; color:#015697" href="https://doi.org/10.1137/19M1301539" target="_blank">SIAM Journal on Scientific Computing</a>, 43, A772–A799, 2021. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/337948990" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2004.02244" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/NHTPver2" target="_blank">Code</a> 
<p style="line-height: 1;"></p>

<details>
<summary><span style="color:#015697"><b style="font-size:16px">Click for more papers</b></span></summary>
<p style="line-height: 1;"></p> 
  
[12] Jun Sun, Lingchen Kong, and Shenglong Zhou, Gradient projection Newton algorithm for sparse collaborative learning, 
  <a style="font-style: italic; color:#015697" href="https://www.sciencedirect.com/science/article/abs/pii/S0377042722004708" target="_blank">Journal of Computational and Applied Mathematics</a>, 422, 1-20, 2022. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/351985058" target="_blank">RG</a>,
 <a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2108.06605" target="_blank">ArXiv</a>
<p style="line-height: 1;"></p>
  
[11] Rui Wang, Naihua Xiu, and  Shenglong Zhou, An extended Newton-type algorithm for L2-regularized sparse logistic regression and its efficiency for classifying large-scale datasets,
<a style="font-style: italic; color:#015697"  href="https://doi.org/10.1016/j.cam.2021.113656" target="_blank">Journal of Computational and Applied Mathematics</a>,  397, 1-17, 2021.
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/330224305" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/1901.02768" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/NSLR" target="_blank">Code</a>
<p style="line-height: 1;"></p>
  
[10] Xinrong Li, Naihua Xiu, and   Shenglong Zhou, Matrix optimization over low-rank spectral sets: stationary points, local and global minimizers,
<a style="font-style: italic; color:#015697" href="https://link.springer.com/article/10.1007%2Fs10957-019-01606-8" target="_blank">Journal of Optimization Theory and Applications</a>, 184, 895–930, 2019.
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/327581904" target="_blank">RG</a> 
<p style="line-height: 1;"></p>

[9] Lili Pan,   Shenglong Zhou, Naihua Xiu, and Huoduo Qi, A convergent iterative hard thresholding for sparsity and nonnegativity constrained optimization,
<a style="font-style: italic; color:#015697"  href="http://www.yokohamapublishers.jp/online2/oppjo/vol13/p325.html" target="_blank">Pacific Journal of Optimization</a>, 13,  325-353, 2017.
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/299519906" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/IIHT" target="_blank">Code</a> 
<p style="line-height: 1;"></p>

[8] Lianjun Zhang, Lingchen Kong, and   Shenglong Zhou, A smoothing iterative method for quantile regression with nonconvex lp Penalty,
<a style="font-style: italic; color:#015697" href="https://aimsciences.org/article/doi/10.3934/jimo.2016006" target="_blank">Journal of Industrial and Management Optimization</a>, 13, 93-112, 2017.
<p style="line-height: 1;"></p>

[7] Yanqing Liu, Guokai Liu, Xianchao Xiu, and   Shenglong Zhou, The L1-penalized quantile regression for traditional Chinese medicine syndrome manifestation,
<a style="font-style: italic; color:#015697" href="http://www.yokohamapublishers.jp/online2/oppjo/vol13/p279.html" target="_blank">Pacific Journal of Optimization</a>, 13, 279-300, 2017.
<p style="line-height: 1;"></p>

[6] Shenglong Zhou, Naihua Xiu, Yingnan Wang, Lingchen Kong, and Huoduo Qi, A Null-space-based weighted l1 minimization approach to compressed sensing,
<a style="font-style: italic; color:#015697"  href="https://academic.oup.com/imaiai/article/5/1/76/2357109" target="_blank">Information and Inference: A Journal of the IMA </a>,  5, 76-102, 2016. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/294109268" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/MIRL1" target="_blank">Code</a> 
<p style="line-height: 1;"></p>

[5] Lili Pan, Naihua Xiu, and   Shenglong Zhou,  On Solutions of Sparsity Constrained Optimization,
<a style="font-style: italic; color:#015697" href="https://link.springer.com/article/10.1007/s40305-015-0101-3" target="_blank">Journal of the Operations Research Society of China</a>, 3, 421-439, 2015. 
<p style="line-height: 1;"></p>

[4] Shenglong Zhou, Naihua Xiu, Ziyan Luo, and Lingchen Kong, Sparse and low-rank covariance matrix estimation,
<a style="font-style: italic; color:#015697"  href="https://link.springer.com/article/10.1007/s40305-014-0058-7" target="_blank">Journal of the Operations Research Society of China</a>,  3, 231-250, 2015.
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/ADMM" target="_blank">Code</a> 
<p style="line-height: 1;"></p>

[3] Meijuan Shang,  Shenglong Zhou, and Naihua Xiu,  Extragradient thresholding methods For sparse solutions of co-coercive NCPs,
<a style="font-style: italic; color:#015697"  href="https://journalofinequalitiesandapplications.springeropen.com/articles/10.1186/s13660-015-0551-5" target="_blank">Journal of Inequalities and Applications</a>, 34, 2015. <a style="font-size: 16px; font-weight: bold;color:#015697" href="\files\ETA.zip" target="_blank">Code</a> 
<p style="line-height: 1;"></p>

[2] Meijuan Shang, Chao Zhang, Dingtao Peng, and   Shenglong Zhou, A half thresholding projection algorithm for sparse solutions of LCPs,
<a style="font-style: italic; color:#015697"  href="https://www.infona.pl/resource/bwmeta1.element.springer-doi-10_1007-S11590-014-0834-7" target="_blank">Optimization Letters</a>,   9, 1231-1245, 2015.
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/HTPCP" target="_blank">Code</a> 
<p style="line-height: 1;"></p>

[1] Shenglong Zhou, Lingchen Kong, and Naihua Xiu,  New bounds for RIC in compressed sensing,
<a style="font-style: italic; color:#015697" href="https://link.springer.com/article/10.1007/s40305-013-0013-z" target="_blank">Journal of the Operations Research Society of China</a>,  1, 227-237, 2013.

</details>
  
</div>
 
</font>

## <b style="font-size:20px"> Machine Learning Related Optimization</b>

<font size=4>
<div style="text-align:justify"> 

[11] Shan Sha, Shenglong Zhou, Lingchen Kong, and Geoffrey Ye Li, Sparse decentralized federated learning, 
<a style="font-style: italic; color:#015697" href="https://ieeexplore.ieee.org/document/11145909" target="_blank">IEEE Transactions on Signal Processing</a>, online, 2025. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/389056587" target="_blank">RG</a>, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2308.16671" target="_blank">ArXiv</a>
<p style="line-height: 1;"></p>

[10] Ouya Wang, Hengtao He, Shenglong Zhou, Zhi Ding, Shi Jin, Khaled Letaief, and Geoffrey Ye Li, Fast adaptation for deep learning-based wireless communications, 
<a style="font-style: italic; color:#015697" href="https://ieeexplore.ieee.org/document/11098646" target="_blank">IEEE Communications Magazine</a>, online, 2025. 
<p style="line-height: 1;"></p>

[9] Shenglong Zhou, Ouya Wang, Ziyan Luo, Yongxu Zhu, and Geoffrey Ye Li, Preconditioned inexact stochastic ADMM for deep models, 2025. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/389024585" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2502.10784" target="_blank">ArXiv</a>
<p style="line-height: 1;"></p>

[8] Ouya Wang, Shenglong Zhou, and Geoffrey Ye Li, BADM: Batch ADMM for deep learning, 2024. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/381922655" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2407.01640" target="_blank">ArXiv</a>
<p style="line-height: 1;"></p>
  
[7] Ouya Wang, Shenglong Zhou, and Geoffrey Ye Li, New environment adaptation with few shots for OFDM receiver and mmWave beamforming, accepted by IEEE Transactions on Signal Processing,  2024. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/374845426" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2310.12343" target="_blank">ArXiv</a>
<p style="line-height: 1;"></p>

[6] Shenglong Zhou and Geoffrey Ye Li, Federated learning via inexact ADMM,
<a style="font-style: italic; color:#015697"  href="https://ieeexplore.ieee.org/document/10040221" target="_blank">IEEE Transactions on Pattern Analysis and Machine Intelligence</a>, 45, 9699-9708, 2023. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/360164168" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2204.10607" target="_blank">ArXiv</a>, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/FedADMM" target="_blank">Code</a>
<p style="line-height: 1;"></p>
  
[5] Shenglong Zhou and Geoffrey Ye Li, FedGiA: An efficient hybrid algorithm for federated learning,
<a style="font-style: italic; color:#015697" href="https://ieeexplore.ieee.org/document/10106001" target="_blank">IEEE Transactions on Signal Processing </a>, 71, 1493-1508, 2023.
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/360353524" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2205.01438" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/FedGiA" target="_blank">Code</a>
<p style="line-height: 1;"></p>  

[4] Kaidi Xu, Shenglong Zhou, and Geoffrey Ye Li, Federated reinforcement learning for resource allocation in V2X networks, 
<a style="font-style: italic; color:#015697"  href="https://ieeexplore.ieee.org/document/10804630" target="_blank">IEEE Journal of Selected Topics in Signal Processing</a>, 18，1210-1221, 2024. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/387143542" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2310.09858" target="_blank">ArXiv</a>
<p style="line-height: 1;"></p>

<details>
<summary><span style="color:#015697"><b style="font-size:16px">Click for more papers</b></span></summary>
<p style="line-height: 1;"></p> 

[3] Kaidi Xu, Shenglong Zhou, and Geoffrey Ye Li, Rescale-invariant federated reinforcement learning for resource allocation in V2X networks, 
<a style="font-style: italic; color:#015697"  href="https://ieeexplore.ieee.org/document/10736393" target="_blank">IEEE Communications Letters</a>, 1-5, 2024. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/385267344" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2405.01961" target="_blank">ArXiv</a>
<p style="line-height: 1;"></p> 

[2] Shenglong Zhou and Geoffrey Ye Li, Exact penalty method for federated learning, 2022. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/362932026" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2208.11231" target="_blank">ArXiv</a>, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/FedEPM" target="_blank">Code</a>
<p style="line-height: 1;"></p>

 <!--- 
[2] Hui Zhang, Shenglong Zhou, Naihua Xiu, and Geoffrey Ye Li, 0/1 Deep neural networks via block coordinate descent, 2022.
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/361411821" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2206.09379" target="_blank">ArXiv</a>
<p style="line-height: 1;"></p> 

[2] Shenglong Zhou and Geoffrey Ye Li, Communication-efficient ADMM-based federated learning, 2021. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/355730311" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2110.15318" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/ICEADMM" target="_blank">Code</a>
<p style="line-height: 1;"></p>
--->
  
[1] Xinyu Wei, Biing-Hwang Fred Juang, Ouya Wang, Shenglong Zhou, and Geoffrey Ye Li, Accretionary learning with deep neural networks,
 <a style="font-style: italic; color:#015697" href="https://ieeexplore.ieee.org/document/10361279" target="_blank">IEEE Transactions on Cognitive Communications and Networking </a>, 2023.
 <a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/340769764" target="_blank">RG</a>,
 <a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2111.10857" target="_blank">ArXiv</a>
<p style="line-height: 1;"></p>

</details>
</div>
</font> 

## <b style="font-size:20px">EDM Optimization</b>

<font size=4> 
<div style="text-align:justify">   
[3] Shenglong Zhou, Naihua Xiu, and Huoduo Qi, Robust Euclidean embedding via EDM optimization,
<a style="font-style: italic; color:#015697"  href="https://link.springer.com/article/10.1007/s12532-019-00168-0" target="_blank">Mathematical Programming Computation</a>, 12, 337–387, 2019. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/PREEEDM" target="_blank">Code</a> 
<p style="line-height: 1;"></p>

[2] Shenglong Zhou, Naihua Xiu, and Huoduo Qi, A fast matrix majorization-projection method for penalized stress minimization with box constraints, 
<a style="font-style: italic; color:#015697"   href="https://ieeexplore.ieee.org/document/8399531" target="_blank">IEEE Transactions on Signal Processing</a>, 66, 4331-4346, 2018. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/SQREDM" target="_blank">Code</a>
<p style="line-height: 1;"></p>

[1] Shenglong Zhou, Majorization-projection methods for multidimensional scaling via Euclidean distance matrix optimization,
<a style="font-style: italic; color:#015697"  href="https://eprints.soton.ac.uk/429739/" target="_blank">PhD Thesis</a>,  University of Southampton, 2018. 
</div></font>


## <b style="font-size:20px">Bilevel Optimization</b>

<font size=4> 
<div style="text-align:justify"> 
[4] Joydeep Dutta, Lafhim Lahoussine, Alain B. Zemkoho, and Shenglong Zhou, Nonconvex quasi-variational inequalities: stability analysis and application to numerical optimization, 
<a style="font-style: italic; color:#015697" href="https://doi.org/10.1007/s10957-024-02582-4" target="_blank">Journal of Optimization Theory and Applications</a>, 204(16), 625-674, 2025.
  <a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/363835556" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2210.02531" target="_blank">ArXiv</a>,
<p style="line-height: 1;"></p> 
  

[3] Alain Zemkoho and   Shenglong Zhou, Theoretical and numerical comparison of the KKT and value function reformulations in bilevel optimization,
<a style="font-style: italic; color:#015697" href="https://doi.org/10.1007/s10589-020-00250-7" target="_blank">Computational Optimization and Application</a>, 78, 625-674, 2021. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/340769764" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2004.10830" target="_blank">ArXiv</a>
<p style="line-height: 1;"></p>

[2] Andreas Fischer, Alain Zemkoho, and   Shenglong Zhou, Semismooth Newton-type method for bilevel optimization: Global convergence and extensive numerical experiments,
<a style="font-style: italic; color:#015697" href="https://www.tandfonline.com/doi/full/10.1080/10556788.2021.1977810" target="_blank"> Optimization Methods and Software</a>, 1-35, 2021. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/337943979" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/1912.07079" target="_blank">ArXiv</a> 
<p style="line-height: 1;"></p>
    
[1] Shenglong Zhou, Alain Zemkoho, and Andrey Tin,  BOLIB 2019: Bilevel Optimization LIBrary of Test Problems Version 2, 2019. 
<a style="font-style: italic; color:#015697"   href="https://www.springer.com/gp/book/9783030521189" target="_blank">Bilevel optimization: advances and next challenges</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://biopt.github.io/files/Paper.pdf" target="_blank">BiOpt</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/338375731" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/1812.00230" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://biopt.github.io/bolib/" target="_blank">Code</a> 

</div></font>


## <b style="font-size:20px">Conference Paper</b>

<font size=4> 
<div style="text-align:justify"> 

[4] Kaidi Xu, Shenglong Zhou, and Geoffrey Ye Li, Federated reinforcement learning for resource allocation in V2X networks, 
<a style="font-style: italic; color:#015697"  href="https://ieeexplore.ieee.org/document/10683304" target="_blank">2024 IEEE 99th Vehicular Technology Conference (VTC2024-Spring)</a>, 1-6, 2024. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/384350685" target="_blank">RG</a>
<p style="line-height: 1;"></p>
 
[3] Shenglong Zhou, Kaidi Xu, and Geoffrey Ye Li, Communication-efficient decentralized federated learning via one-bit compressive sensing, 
<a style="font-style: italic; color:#015697" href="https://ieeexplore.ieee.org/document/10683577" target="_blank">2024 IEEE 99th Vehicular Technology Conference (VTC2024-Spring) </a>, 2024. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/373526540" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2308.16671" target="_blank">ArXiv</a>
<p style="line-height: 1;"></p>

[2] Ouya Wang, Shenglong Zhou, and Geoffrey Ye Li, Effective adaptation into new environment with few shots: Applications to OFDM receiver design,
<a style="font-style: italic; color:#015697" href="https://ieeexplore.ieee.org/document/10285904/" target="_blank">2023 IEEE 33rd International Workshop on Machine Learning for Signal Processing (MLSP)</a>, 2023. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/374933177" target="_blank">RG</a>
(Top 5% Outstanding Paper)
<p style="line-height: 1;"></p>

[1] Ouya Wang, Shenglong Zhou, and Geoffrey Ye Li, Few-shot learning for new environment adaptation,
<a style="font-style: italic; color:#015697" href="https://ieeexplore.ieee.org/document/10437273/" target="_blank">2023 IEEE Global Communications Conference</a>, 2023.
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/378501268" target="_blank">RG</a>
<p style="line-height: 1;"></p>
  
</div></font>



<!---

## <b style="font-size:20px">Sparse Optimization</b>
---

<font size=4> 
<div style="text-align:justify"> 
 Shenglong Zhou, IEEE Transactions on Pattern Analysis and Machine Intelligence, 2021 <br>
<i>Sparse SVM for sufficient data reduction</i>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://ieeexplore.ieee.org/document/9415153" target="_blank">TPAMI</a>, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/351035522" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2005.13771" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/NSSVM" target="_blank">Code</a> 
<p style="line-height: 1;"></p>
  
 Shenglong Zhou, Naihua Xiu and Huoduo Qi, Journal of Machine Learning Research, 22(12):1−45, 2021<br>
<i>Global and quadratic convergence of Newton hard-thresholding pursuit</i>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://jmlr.org/papers/v22/19-026.html" target="_blank">JMLR</a>, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/330224407" target="_blank">RG</a>, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/1901.02763" target="_blank">ArXiv</a>, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/NHTPver2" target="_blank">Code</a>
<p style="line-height: 1;"></p>
  
 Shenglong Zhou, Lili Pan and Naihua Xiu,  Numerical Algorithms, 2021 <br>
<i>Newton method  for L0-regularized optimization</i>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://doi.org/10.1007/s11075-021-01085-x" target="_blank">NumAlg</a>, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/340563338" target="_blank">RG</a>, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2004.05132" target="_blank">ArXiv</a>, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/NL0R" target="_blank">Code</a> 
<p style="line-height: 1;"></p>
  
 Shenglong Zhou, Lili Pan, M. Li and Meijuan Shang, SIAM Journal on Scientific Computing, 43(2), A772–A799, 2021 <br>
<i>Newton hard-thresholding pursuit for sparse LCP via a new merit function</i>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://doi.org/10.1137/19M1301539" target="_blank">SISC</a>, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/337948990" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2004.02244" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/NHTPver2" target="_blank">Code</a> 
<p style="line-height: 1;"></p>
      
J. Sun, Lingchen Kong and   Shenglong Zhou, 2021 <br>
<i>Gradient Projection Newton Algorithm for Sparse Collaborative Learnings</i>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/351985058" target="_blank">RG</a>
<p style="line-height: 1;"></p>
  
R. Wang, Naihua Xiu and   Shenglong Zhou, Journal of Computational and Applied Mathematics, 397, 1-17, 2021 <br>
<i>An extended Newton-type algorithm for L2-regularized sparse logistic regression and its efficiency for classifying large-scale datasets</i>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://doi.org/10.1016/j.cam.2021.113656" target="_blank">JCAM</a>, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/330224305" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/1901.02768" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/NSLR" target="_blank">Code</a>
<p style="line-height: 1;"></p>
  
 X.R. Li, Naihua Xiu and   Shenglong Zhou, Journal of Optimization Theory and Applications, 184, 895–930, 2019 <br>
<i>Matrix optimization over low-rank spectral sets: stationary points, local and global minimizers</i>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://link.springer.com/article/10.1007%2Fs10957-019-01606-8" target="_blank">JOTA</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/327581904" target="_blank">RG</a> 
<p style="line-height: 1;"></p>

Lili Pan,   Shenglong Zhou, Naihua Xiu and Huoduo Qi, Pacific Journal of Optimization,  13(2): 325-353, 2017 <br>
<i>A convergent iterative hard thresholding for sparsity and nonnegativity constrained optimization</i>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="http://www.yokohamapublishers.jp/online2/oppjo/vol13/p325.html" target="_blank">PJO</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/299519906" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/IIHT" target="_blank">Code</a> 
<p style="line-height: 1;"></p>

L.J. Zhang, Lingchen Kong and   Shenglong Zhou, Journal of Industrial and Management Optimization,   13 (1): 93 - 112, 2017 <br>
<i>A smoothing iterative method for quantile regression with nonconvex lp Penalty</i>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://aimsciences.org/article/doi/10.3934/jimo.2016006" target="_blank">JIMO</a> 
<p style="line-height: 1;"></p>

Y.Q. Liu, G.K. Liu, X.C. Xiu and   Shenglong Zhou, Pacific Journal of Optimization,   13(2): 279-300, 2017 <br>
<i>The L1-penalized quantile regression for traditional Chinese medicine syndrome manifestation</i>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="http://www.yokohamapublishers.jp/online2/oppjo/vol13/p279.html" target="_blank">PJO</a> 
<p style="line-height: 1;"></p>

 Shenglong Zhou, Naihua Xiu, Y.N. Wang, Lingchen Kong and Huoduo Qi, Information and Inference,  5(1): 76-102, 2016 <br>
<i>A Null-space-based weighted l1 minimization approach to compressed sensing</i>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://academic.oup.com/imaiai/article/5/1/76/2357109" target="_blank">IMAIAI</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/294109268" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/MIRL1" target="_blank">Code</a> 
<p style="line-height: 1;"></p>

Lili Pan, Naihua Xiu and   Shenglong Zhou, Journal of the Operations Research Society of China,  3(4): 421-439, 2015 <br>
<i>On Solutions of Sparsity Constrained Optimization</i>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://link.springer.com/article/10.1007/s40305-015-0101-3" target="_blank">JORSC</a> 
<p style="line-height: 1;"></p>

 Shenglong Zhou, Naihua Xiu, Ziyan Luo and Lingchen Kong, Journal of the Operations Research Society of China,  3(2): 231-250, 2015 <br>
<i>Sparse and low-rank covariance matrix estimation</i>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://link.springer.com/article/10.1007/s40305-014-0058-7" target="_blank">JORSC</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/ADMM" target="_blank">Code</a> 
<p style="line-height: 1;"></p>

Meijuan Shang,  Shenglong Zhou and Naihua Xiu, Journal of Inequalities and Applications,  34, 2015 <br>
<i>Extragradient thresholding methods For sparse solutions of co-coercive NCPs</i>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://journalofinequalitiesandapplications.springeropen.com/articles/10.1186/s13660-015-0551-5" target="_blank">JIA</a> 
<p style="line-height: 1;"></p>

Meijuan Shang, C. Zhang, D.T. Peng and   Shenglong Zhou, Optimization Letters,  9(6): 1231-1245, 2015 <br>
<i>A half thresholding projection algorithm for sparse solutions of LCPs</i>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.infona.pl/resource/bwmeta1.element.springer-doi-10_1007-S11590-014-0834-7" target="_blank">OPLE</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/HTPCP" target="_blank">Code</a> 
<p style="line-height: 1;"></p>

 Shenglong Zhou, Lingchen Kong and Naihua Xiu, Journal of the Operations Research Society of China,  1(2): 227-237, 2013 <br>
<i>New bounds for RIC in compressed sensing</i>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://link.springer.com/article/10.1007/s40305-013-0013-z" target="_blank">JORSC</a>

</font>



## <b style="font-size:20px"> 0/1 Loss Optimization</b>
---

<font size=4>
 Shenglong Zhou, Lili Pan, Naihua Xiu and Huoduo Qi, 2021 <br>
<i>Quadratic convergence of Newton's method for 0/1 loss optimization</i>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/350442413" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2103.14987" target="_blank">ArXiv</a>
<p style="line-height: 1;"></p>

 Shenglong Zhou, Lili Pan and Naihua Xiu, 2020 <br>
<i>Heaviside set constrained optimization: optimality and Newton method</i>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/343362652" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2007.15737" target="_blank">ArXiv</a>
<p style="line-height: 1;"></p>

 Shenglong Zhou, Ziyan Luo and Naihua Xiu, 2021 <br> 
<i>Computing one-bit compressive sensing via double-sparsity constrained optimization</i>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/348371863" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2101.03599" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/GPSP" target="_blank">Code</a> 
<p style="line-height: 1;"></p>

H.J. Wang, Y.H. Shao,  Shenglong Zhou, C. Zhang and Naihua Xiu, 2019 <br>
<i>Support vector machine classifier via L0/1 soft-margin loss</i>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/338717629" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/1912.07418" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/Huajun-Wang/L01ADMM" target="_blank">Code</a>
</font> 


## <b style="font-size:20px">EDM Optimization</b>
---

<font size=4> 
 Shenglong Zhou, Naihua Xiu and Huoduo Qi, Mathematical Programming Computation, 12(3): 337–387, 2019<br>
<i>Robust euclidean embedding via EDM optimization</i>, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://link.springer.com/article/10.1007/s12532-019-00168-0" target="_blank">MPC</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/PREEEDM" target="_blank">Code</a> 
<p style="line-height: 1;"></p>

 Shenglong Zhou, Naihua Xiu and Huoduo Qi, IEEE Transactions on Signal Processing,  66(16): 4331-4346, 2018<br> 
<i>A fast matrix majorization-projection method for penalized stress minimization with box constraints</i>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://ieeexplore.ieee.org/document/8399531" target="_blank">TSP</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/SQREDM" target="_blank">Code</a>
<p style="line-height: 1;"></p>

 Shenglong Zhou, Naihua Xiu and Huoduo Qi, PhD Thesis, University of Southampton, 2018<br>
<i>Majorization-projection methods for multidimensional scaling via Euclidean distance matrix optimization</i>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://eprints.soton.ac.uk/429739/" target="_blank">Soton</a>  
</font>


## <b style="font-size:20px">Bilevel Optimization</b>
---

<font size=4> 
Alain Zemkoho and   Shenglong Zhou, Computational Optimization and Application, 78(2), 625-674, 2021, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://doi.org/10.1007/s10589-020-00250-7" target="_blank">JCOA</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/340769764" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2004.10830" target="_blank">ArXiv</a> 
<br>
<i>Theoretical and numerical comparison of the KKT and value function reformulations in bilevel optimization</i> 

<p style="line-height: 1;"></p>

 Shenglong Zhou, Alain Zemkoho and A. Tin, Bilevel optimization: advances and next challenges, 2019 <br> 
<i>BOLIB 2019: Bilevel Optimization LIBrary of Test Problems Version 2</i>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://biopt.github.io/files/Paper.pdf" target="_blank">BiOpt</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.springer.com/gp/book/9783030521189" target="_blank">Book</a>, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/338375731" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/1812.00230" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://biopt.github.io/bolib/" target="_blank">Code</a> 
<p style="line-height: 1;"></p>

A. Fischer, Alain Zemkoho and   Shenglong Zhou, 2019, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/337943979" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/1912.07079" target="_blank">ArXiv</a>  <br>
<i>Semismooth Newton-type method for bilevel optimization: Global convergence and extensive numerical experiments</i> 

</font>

--->




