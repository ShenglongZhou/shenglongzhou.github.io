---
layout: single
title: ""
permalink: /CNabout/
author_profile: true
redirect_from:
  - /resume
---

<style>
a:link {
  text-decoration: none;
}

a:visited {
  text-decoration: none;
}

a:hover {
  text-decoration: underline;
}

a:active {
  text-decoration: underline;
}
</style>



<b style="font-size:20px">工作经历</b>
---
2023-03 至今，北京交通大学，数学与统计学院，教授 <br>
2021-06 至 2023-03，伦敦帝国理工学院，工程学院，副研究员 <br>
2020-02 至 2021-02，英国南安普顿大学，数学学院，讲师 <br>
2017-10 至 2020-01，英国南安普顿大学，数学学院，副研究员 

<b style="font-size:20px">教育背景</b>
---
2014-10 至 2018-12，博士，英国南安普顿大学，运筹学  <br>
2011-09 至 2014-03，硕士，北京交通大学，运筹学与控制论 <br> 
2007-09 至 2011-06，学士，北京交通大学， 信息与计算科学 

<b style="font-size:20px">研究兴趣</b> 
---
<p><div style="text-align:justify;"> 
最优化理论与算法：包括稀疏阶跃和分布式优化，以及在人工智能等领域中的应用 <br>

招收最优化、人工智能、机器学习等领域博士后、博士、以及硕士
</div></p> 

<b style="font-size:20px">计算平台</b>
---

稀疏优化计算平台 - <a style="font-size: 16px; font-weight: bold; color:#015697"  href="https://sparseopt.github.io/" target="_blank">SparseOpt</a><br>
双层规划计算平台 - <a style="font-size: 16px; font-weight: bold; color:#015697"  href="https://biopt.github.io/" target="_blank">BiOpt</a>

<b style="font-size:20px">代表性论文</b>
---
全部发表文章可参考 - <a style="font-size: 16px; font-weight: bold; color:#015697"  href="https://shenglongzhou.github.io/publications/" target="_blank">全部文章</a>

<font size=4>
<div style="text-align:justify"> 

[10] Shenglong Zhou, Lili Pan, Naihua Xiu, and Geoffrey Ye Li, A 0/1 constrained optimization solving sample average approximation for chance constrained programming, <a style="font-style: italic; color:#015697" href="https://pubsonline.informs.org/doi/10.1287/moor.2023.0149" target="_blank">Mathematics of Operations Research</a>, 2024. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/364588009" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2210.11889" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/SNSCO" target="_blank">Code</a>
<p style="line-height: -0.5em"></p>

[9] Shenglong Zhou and Geoffrey Ye Li, Federated learning via inexact ADMM,
<a style="font-style: italic; color:#015697"  href="https://ieeexplore.ieee.org/document/10040221" target="_blank">IEEE Transactions on Pattern Analysis and Machine Intelligence</a>, 45, 9699-9708, 2023. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/360164168" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2204.10607" target="_blank">ArXiv</a>, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/FedADMM" target="_blank">Code</a>
 <p style="line-height:-0.5em"></p>
  
[8] Shenglong Zhou, Sparse SVM for sufficient data reduction, 
<a style="font-style: italic; color:#015697" href="https://ieeexplore.ieee.org/document/9415153" target="_blank">IEEE Transactions on Pattern Analysis and Machine Intelligence</a>, 44, 5560-5571, 2022. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/351035522" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2005.13771" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/NSSVM" target="_blank">Code</a> 
<p style="line-height: 1;"></p>
  
[7] Shenglong Zhou, Gradient projection newton pursuit for sparsity constrained optimization, 
<a style="font-style: italic; color:#015697" href="https://doi.org/10.1016/j.acha.2022.06.002" target="_blank">Applied and Computational Harmonic Analysis</a>, 61, 75-100, 2022. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/360476606" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2205.04580" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/GPNP" target="_blank">Code</a> 
<p style="line-height: 1;"></p>
  
[6] Shenglong Zhou, Ziyan Luo, Naihua Xiu and Geoffrey Ye Li, Computing one-bit compressive sensing via double-sparsity constrained optimization, 
<a style="font-style: italic; color:#015697" href="https://ieeexplore.ieee.org/document/9729395" target="_blank">IEEE Transactions on Signal Processing</a>, 70, 1593-1608, 2022.
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/348371863" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2101.03599" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/GPSP" target="_blank">Code</a> 
<p style="line-height: 1;"></p>
  
[5] Shenglong Zhou, Lili Pan, Naihua Xiu and Huoduo Qi, Quadratic convergence of smoothing Newton's method for 0/1 loss optimization, 
<a style="font-style: italic; color:#015697" href="https://epubs.siam.org/doi/abs/10.1137/21M1409445" target="_blank">SIAM Journal on Optimization</a>, 31, 3184–3211, 2021. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/354744779" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2103.14987" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/NM01" target="_blank">Code</a>
<p style="line-height: 1;"></p>

[4] Shenglong Zhou, Lili Pan, Mu Li, and Meijuan Shang, Newton hard-thresholding pursuit for sparse linear complementarity problem via a new merit function, 
<a style="font-style: italic; color:#015697" href="https://doi.org/10.1137/19M1301539" target="_blank">SIAM Journal on Scientific Computing</a>, 43, A772–A799, 2021. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/337948990" target="_blank">RG</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/2004.02244" target="_blank">ArXiv</a>,
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/NHTPver2" target="_blank">Code</a> 
<p style="line-height: 1;"></p>

[3] Shenglong Zhou, Naihua Xiu and Huoduo Qi, Global and quadratic convergence of Newton hard-thresholding pursuit, 
<a style="font-style: italic; color:#015697" href="https://jmlr.org/papers/v22/19-026.html" target="_blank">Journal of Machine Learning Research</a>, 22, 1−45, 2021. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://www.researchgate.net/publication/330224407" target="_blank">RG</a>, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://arxiv.org/abs/1901.02763" target="_blank">ArXiv</a>, 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/NHTPver2" target="_blank">Code</a>
<p style="line-height: 1;"></p>
  
[2] Shenglong Zhou, Naihua Xiu and Huoduo Qi, Robust Euclidean embedding via EDM optimization,
<a style="font-style: italic; color:#015697"  href="https://link.springer.com/article/10.1007/s12532-019-00168-0" target="_blank">Mathematical Programming Computation</a>, 12, 337–387, 2019. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/PREEEDM" target="_blank">Code</a> 
<p style="line-height: 1;"></p>

[1] Shenglong Zhou, Naihua Xiu and Huoduo Qi, A fast matrix majorization-projection method for penalized stress minimization with box constraints, 
<a style="font-style: italic; color:#015697"   href="https://ieeexplore.ieee.org/document/8399531" target="_blank">IEEE Transactions on Signal Processing</a>, 66, 4331-4346, 2018. 
<a style="font-size: 16px; font-weight: bold;color:#015697" href="https://github.com/ShenglongZhou/SQREDM" target="_blank">Code</a>
<p style="line-height: 1;"></p>

</div>
</font> 

<b style="font-size:20px">科研项目</b>
---
2023-2028，主持，300万元，国家重点研发计划，海量数据分析中的阶跃稀疏优化理论与方法 <br>
2023-2026，主持，100万元，其他部市，机器学习中的0/1损失优化理论与二阶算法研究 <br>
2023-2026，主持，100万元，自然科学类人才基金项目， 联邦学习中的最优化算法理论与应用  

<b style="font-size:20px">获奖与荣誉</b>
---
2023年，IEEE MLSP 杰出论文奖 <br>
2022年，入选国家级青年人才计划 <br>
2019年，新世界数学奖博士论文优胜奖
